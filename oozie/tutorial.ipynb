{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Oozie\n",
    "Apache Oozie is a Hadoop job scheduler that allows to combine multiple complex jobs to be run in a sequential order to achieve a bigger task. Within a sequence of task, two or more jobs can also be programmed to run parallel to each other.\n",
    "\n",
    "## The 3 types of jobs\n",
    "Oozie `Workflow` Jobs − These are represented as Directed Acyclic Graphs (DAGs) to specify a sequence of actions to be executed.\n",
    "\n",
    "Oozie `Coordinator` Jobs − These consist of workflow jobs triggered by time and data availability.\n",
    "\n",
    "Oozie `Bundle` − These can be referred to as a package of multiple coordinator and workflow jobs.\n",
    "\n",
    "~[](https://www.tutorialspoint.com/apache_oozie/images/sample_workflow.jpg)\n",
    "\n",
    "## Workflow\n",
    "A workflow action can be a **Hive action, Pig action, Java action, Shell action**, etc. We can include `fork` and `decisions`.\n",
    "\n",
    "example workflow:\n",
    "```xml\n",
    "<!-- This is a comment -->\n",
    "<workflow-app xmlns = \"uri:oozie:workflow:0.4\" name = \"simple-Workflow\">\n",
    "   <start to = \"fork_node\" />\n",
    "   \n",
    "   <fork name = \"fork_node\">\n",
    "      <path start = \"Create_External_Table\"/>\n",
    "      <path start = \"Create_orc_Table\"/>\n",
    "   </fork>\n",
    "   \n",
    "   <action name = \"Create_External_Table\">\n",
    "      <hive xmlns = \"uri:oozie:hive-action:0.4\">\n",
    "         <job-tracker>xyz.com:8088</job-tracker>\n",
    "         <name-node>hdfs://rootname</name-node>\n",
    "         <script>hdfs_path_of_script/external.hive</script>\n",
    "      </hive>\n",
    "      \n",
    "      <ok to = \"join_node\" />\n",
    "      <error to = \"kill_job\" />\n",
    "   </action>\n",
    "   \n",
    "   <action name = \"Create_orc_Table\">\n",
    "      <hive xmlns = \"uri:oozie:hive-action:0.4\">\n",
    "         <job-tracker>xyz.com:8088</job-tracker>\n",
    "         <name-node>hdfs://rootname</name-node>\n",
    "         <script>hdfs_path_of_script/orc.hive</script>\n",
    "      </hive>\n",
    "\t\t\n",
    "      <ok to = \"join_node\" />\n",
    "      <error to = \"kill_job\" />\n",
    "   </action>\n",
    "   \n",
    "   <join name = \"join_node\" to = \"Insert_into_Table\"/>\n",
    "\t\n",
    "   <action name = \"Insert_into_Table\">\n",
    "      <hive xmlns = \"uri:oozie:hive-action:0.4\">\n",
    "         <job-tracker>xyz.com:8088</job-tracker>\n",
    "         <name-node>hdfs://rootname</name-node>\n",
    "         <script>hdfs_path_of_script/Copydata.hive</script>\n",
    "         <param>database_name</param>\n",
    "      </hive>\n",
    "\t\t\n",
    "      <ok to = \"end\" />\n",
    "      <error to = \"kill_job\" />\n",
    "   </action>\n",
    "   \n",
    "   <kill name = \"kill_job\">\n",
    "      <message>Job failed</message>\n",
    "   </kill>\n",
    "   \n",
    "   <end name = \"end\" />\n",
    "\t\n",
    "</workflow-app>\n",
    "```\n",
    "which produces the following DAG\n",
    "\n",
    "![](https://www.tutorialspoint.com/apache_oozie/images/workflow.jpg)\n",
    "\n",
    "### Property File\n",
    "We can specify a `.properties` config file. Variables like `${nameNode}` can be passed within the workflow definition.\n",
    "\n",
    "job1.properties\n",
    "```\n",
    "nameNode = hdfs://rootname\n",
    "jobTracker = xyz.com:8088\n",
    "script_name_external = hdfs_path_of_script/external.hive\n",
    "script_name_orc=hdfs_path_of_script/orc.hive\n",
    "script_name_copy=hdfs_path_of_script/Copydata.hive\n",
    "database = database_name\n",
    "```\n",
    "\n",
    "## Running the job\n",
    "```shell\n",
    "oozie job \\\n",
    "    --oozie http://host_name:8080/oozie \\\n",
    "    --config edgenode_path/job1.properties \\\n",
    "    -D oozie.wf.application.path hdfs://Namenodepath/pathof_workflow_xml/workflow.xml \\\n",
    "    –run\n",
    "```\n",
    "\n",
    "Note − The property file should be on the edge node (not in HDFS), whereas the workflow and hive scripts will be in HDFS.\n",
    "\n",
    "## Coordinator\n",
    "Coordinator applications allow users to schedule complex workflows, including workflows that are scheduled regularly. Oozie Coordinator models the workflow execution triggers in the form of time, data or event predicates. The workflow job mentioned inside the Coordinator is started only after the given conditions are satisfied.\n",
    "\n",
    "Example coordinator:\n",
    "```xml\n",
    "<coordinator-app xmlns = \"uri:oozie:coordinator:0.2\" name =\n",
    "   \"coord_copydata_from_external_orc\" frequency = \"5 * * * *\" start =\n",
    "   \"2016-00-18T01:00Z\" end = \"2025-12-31T00:00Z\" timezone = \"America/Los_Angeles\">\n",
    "   \n",
    "   <controls>\n",
    "      <timeout>1</timeout>\n",
    "      <concurrency>1</concurrency>\n",
    "      <execution>FIFO</execution>\n",
    "      <throttle>1</throttle>\n",
    "   </controls>\n",
    "   \n",
    "   <action>\n",
    "      <workflow>\n",
    "         <app-path>pathof_workflow_xml/workflow.xml</app-path>\n",
    "      </workflow>\n",
    "   </action>\n",
    "\t\n",
    "</coordinator-app>\n",
    "```\n",
    "\n",
    "start − It means the start datetime for the job. Starting at this time the actions will be materialized.\n",
    "\n",
    "end − The end datetime for the job. When actions will stop being materialized.\n",
    "\n",
    "timezone − The timezone of the coordinator application.\n",
    "\n",
    "frequency − The frequency, in minutes, to materialize actions.\n",
    "\n",
    "### Control\n",
    "timeout − The maximum time, in minutes, that a materialized action will be waiting for the additional conditions to be satisfied before being discarded. A timeout of 0 indicates that at the time of materialization all the other conditions must be satisfied, else the action will be discarded. A timeout of 0 indicates that if all the input events are not satisfied at the time of action materialization, the action should timeout immediately. A timeout of -1 indicates no timeout, the materialized action will wait forever for the other conditions to be satisfied. The default value is -1.\n",
    "\n",
    "concurrency − The maximum number of actions for this job that can be running at the same time. This value allows to materialize and submit multiple instances of the coordinator app, and allows operations to catchup on delayed processing. The default value is 1.\n",
    "\n",
    "execution − Specifies the execution order if multiple instances of the coordinator job have satisfied their execution criteria. Valid values are\n",
    "    - FIFO (oldest first) default.\n",
    "    - LIFO (newest first).\n",
    "    - LAST_ONLY (discards all older materializations).\n",
    "    \n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

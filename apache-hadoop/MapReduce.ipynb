{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce\n",
    "MapReduce is a programming model for data processing. MapReduce programs are inherently parallel, thus putting very large-scale data analysis into the hands of anyone with enough machines at their disposal.\n",
    "\n",
    "## The problem with parallel processing\n",
    "1. file sizes vary, so processing time is limited by the longest file. A better approache is to split data into equal sized chunks\n",
    "2. combining the result from different processes\n",
    "3. processing on mulitple machines brings on problems like coordination and reliability\n",
    "\n",
    "## MapReduce: an overview\n",
    "A MapReduce program need three things: a map function, a reduce function, and some code to run the job.\n",
    "\n",
    "### Datatypes\n",
    "Hadoop uses its own datatypes found in the `org.apache.hadoop.io` package.\n",
    "\n",
    "### Context\n",
    "A `Context` instance is mainly used to write the output.\n",
    "\n",
    "### Mapper\n",
    "The `Mapper` class is a generic type, with four formal type parameters that specify the input key, input value, output key, and output value types of the map function. The `map()` method is passed a key and a value.\n",
    "\n",
    "### Reducer\n",
    "Like `Mapper`, four formal type parameters are used to specify the input and output types, this time for the reduce function. Output from the `Mapper` are grouped by their keys before being sent to the input of the `Reducer`.\n",
    "\n",
    "### Job\n",
    "A Job object forms the specification of the job and gives you control over how the job is run. \n",
    "Usual setup:\n",
    "- The `setJarByClass()` method tell hadoop to look for the relevant Jar files containing this class.\n",
    "- The `addInputPath()` method adds input files/directories/file patterns.\n",
    "- The `setOutputPath()` sets the output path. This directory shouldn't exist before the program is run.\n",
    "- specify the map and reduce types to use via the `setMapperClass()` and `setReducerClass()` methods.\n",
    "- The `setOutputKeyClass()` and `setOutputValueClass()` methods control the output types for the reduce function, and must match what the Reduce class produces. The map output types default to the same types, so they do not need to be set if the mapper produces the same types as the reducer (as it does in our case). However, if they are different, the map output types must be set using the `setMapOutputKeyClass()` and `setMapOutputValueClass()` methods.\n",
    "\n",
    "\n",
    "## Example: A simple MapReduce program\n",
    "this program takes temperature data as input and find the maximum temperature for each year.\n",
    "\n",
    "`Mapper`:\n",
    "```java\n",
    "public class MaxTemperatureMapper\n",
    "    extends Mapper<LongWritable, Text, Text, IntWritable> {\n",
    "\n",
    "  private static final int MISSING = 9999;\n",
    "  \n",
    "  @Override\n",
    "  public void map(LongWritable key, Text value, Context context)\n",
    "      throws IOException, InterruptedException {\n",
    "    \n",
    "    String line = value.toString();\n",
    "    String year = line.substring(15, 19);\n",
    "    int airTemperature;\n",
    "    if (line.charAt(87) == '+') { // parseInt doesn't like leading plus signs\n",
    "      airTemperature = Integer.parseInt(line.substring(88, 92));\n",
    "    } else {\n",
    "      airTemperature = Integer.parseInt(line.substring(87, 92));\n",
    "    }\n",
    "    String quality = line.substring(92, 93);\n",
    "    if (airTemperature != MISSING && quality.matches(\"[01459]\")) {\n",
    "      context.write(new Text(year), new IntWritable(airTemperature));\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "`Reducer`:\n",
    "```java\n",
    "public class MaxTemperatureReducer\n",
    "    extends Reducer<Text, IntWritable, Text, IntWritable> {\n",
    "  \n",
    "  @Override\n",
    "  public void reduce(Text key, Iterable<IntWritable> values, Context context)\n",
    "      throws IOException, InterruptedException {\n",
    "    \n",
    "    int maxValue = Integer.MIN_VALUE;\n",
    "    for (IntWritable value : values) {\n",
    "      maxValue = Math.max(maxValue, value.get());\n",
    "    }\n",
    "    context.write(key, new IntWritable(maxValue));\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "`Driver`:\n",
    "```java\n",
    "public static void main(String[] args) throws Exception {\n",
    "    if (args.length != 2) {\n",
    "      System.err.println(\"Usage: MaxTemperature <input path> <output path>\");\n",
    "      System.exit(-1);\n",
    "    }\n",
    "    \n",
    "    Job job = new Job();\n",
    "    job.setJarByClass(MaxTemperature.class);\n",
    "    job.setJobName(\"Max temperature\");\n",
    "\n",
    "    FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "    FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "    \n",
    "    job.setMapperClass(MaxTemperatureMapper.class);\n",
    "    job.setReducerClass(MaxTemperatureReducer.class);\n",
    "\n",
    "    job.setOutputKeyClass(Text.class);\n",
    "    job.setOutputValueClass(IntWritable.class);\n",
    "    \n",
    "    System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

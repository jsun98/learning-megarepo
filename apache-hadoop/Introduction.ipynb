{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "## What is Hadoop\n",
    "A reliable, scalable platform for storage and analysis that is affordable and runs on commodity hardware. Hadoop consists of the `Hadoop Distributed File System` (HDFS) and `MapReduce`, a programming model used for batch processing. \n",
    "\n",
    "## Hadoop vs RDBMS\n",
    "Hadoop\n",
    "    - large scale batch processing on the entire dataset, not suitable for real time data processing\n",
    "    - non-structured and semi-strcutured data\n",
    "    - petabytes of data\n",
    "    - schema-on-read\n",
    "    - scales linearly\n",
    "    - scales horizontally (more nodes)\n",
    "    - data locality\n",
    "    - write once, read many times\n",
    "    - disk transfer rate (streaming data)\n",
    "\n",
    "RDBMS\n",
    "    - real time data processing, point queries and updates on an indexed, relatively small dataset, not suitable for batch processing\n",
    "    - structured data\n",
    "    - gigabytes of data\n",
    "    - schema-on-write\n",
    "    - scales nonlinearly \n",
    "    - scales vertically (more memory/cpu)\n",
    "    - read and write many times\n",
    "    - disk seek (moving the read head)\n",
    "    \n",
    "## Definitions\n",
    "**Schema-On-Write**: creating a schema before writing into the database. `Extract Transform Load (ETL)` is performed to get data into the database. This is a big overhead for inserting data into RDBMS.\n",
    "\n",
    "**Schema-On-Read**: creating a schema only on read. Strucuture is applied only when it's read. This allows unstructured data to be stored in the database. Therefore, the overhead on read is much larger.\n",
    "\n",
    "**Structured Data**: structured data is comprised of clearly defined data types whose pattern makes them easily searchable via algorithms. Fields store length-delineated data phone numbers, Social Security numbers, or ZIP codes. \n",
    "\n",
    "**Unstructured Data**: has no pre-defined data model. comprised of data that is usually not as easily searchable, including formats like audio, video, and social media postings.\n",
    "\n",
    "**Semi-structured Data**: maintains internal tags and markings that identify separate data elements, which enables information grouping and hierarchies. Exampels are emails (because of metadata), XML, JSON, NOSQL.\n",
    "\n",
    "**Data Integrity**: Data integrity is the maintenance of, and the assurance of the accuracy and consistency of, data over its entire life-cycle, and is a critical aspect to the design, implementation and usage of any system which stores, processes, or retrieves data.\n",
    "\n",
    "**Database Normalization**: Database normalization is process used to organize a database into tables and columns.  The idea is that a table should be about a specific topic and that only those columns which support that topic are included. There are three main reasons to normalize a database.  The first is to minimize duplicate data, the second is to minimize or avoid data modification issues, and the third is to simplify queries. \n",
    "\n",
    "**Data Locality**: the idea of moving computation close to where the acutal data resides on the node, instead of moving data to computation. This recognizes network bandwidth as a precious resource. \n",
    "\n",
    "\n",
    "## History and Numbers\n",
    "- Created by Doug Cutting\n",
    "- Hadoop had its origins in Apache Nutch, an open source web search engine\n",
    "- In 2005, the Nutch Distributed Filesystem (NDFS) was developed using MapReduce and ideas from the Google File System\n",
    "- In Febuary 2006, Hadoop became an independent project \n",
    "- In 2006, Doug Cutting joined Yahoo!\n",
    "- In 2008, Hadoop was put into production at Yahoo! Search\n",
    "- In 2008, Hadoop become the fastest system to sort an entire terabyte of data. Running on a 910-node cluster, Hadoop sorted 1 terabyte in 209 seconds\n",
    "- In 2009, a team at Yahoo! had used Hadoop to sort 1 terabyte in 62 seconds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
